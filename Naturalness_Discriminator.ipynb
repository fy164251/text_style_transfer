{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naturalness_Discriminator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOnanQvM-5iz",
        "colab_type": "text"
      },
      "source": [
        "# <center> Style Transfer Evaluation </center>\n",
        "\n",
        "Since our intention is to provide machine-based style transfer, we need to task ourselves with subjectof output evaluation.  It follows from our discussion on styling that such score should include themeasures of a triplet {*style source, narrative fluency, and content equivalence*}. Provided that our ultimate goal is a perfect imitation of source style conditioned on story from content source, missing either of the aforementioned factors will not yield a satisfactory result.For one example, if the output text does not employ the vocabulary and sentence structure of style donor, it will result in the stylistic miss.  For another example, if the output employs the style but departs from the content, it will fail to form a parallel representation.  For a third example, if the output text successfully fuses the content with style of input sources but violates general languageand writing norms, it will result in a poor reading experience. Therefore, to evaluate the quality ofstyle transfer, we need to take all those considerations into account.\n",
        "\n",
        "In evaluating results of the literature style transfer, we must consider that the two dimensions of the metric (naturalness and content preservation) are of the satisficing type, while the style is the metric component we optimize for. We leverage the work done by Mir et. al [1] where the authors propose - \n",
        "\n",
        "* Style Transfer Intensity \n",
        "* Naturalness\n",
        "* Content preservation \n",
        "\n",
        "as key aspects of interest for style transfer for text. The authors propose a set of metrics for automated evaluation and demonstrate that they are are more strongly correlated and in agreement with human judgement than prior work in the area for the respective aspects. We leverage one of these automated metrics these automated metrics obtained via adversarial classification to denote naturalness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HO9ban-pt5W",
        "colab_type": "code",
        "outputId": "1d96c1ca-49f7-40cd-fea6-fa4a955bcc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EStghsVkfG_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "from tokenizer import tokenize\n",
        "from tokenizer import RE_PATTERN\n",
        "from collections import Counter\n",
        "from keras.models import load_model as load_keras_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.externals import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVGVM3zCWMV",
        "colab_type": "text"
      },
      "source": [
        "# Naturalness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBJS7-3YC_ed",
        "colab_type": "code",
        "outputId": "67995ea4-667b-4676-908f-59a96b44a157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\"\"\"EVALUATION OF NATURALNESS\n",
        "This is used to evaluate the naturalness of output texts of our style transfer model.\n",
        "For a baseline understanding of what is considered \"natural,\" any method used for automated evaluation of naturalness\n",
        "also requires an understanding of the human-sourced input texts.\n",
        "Inspired by the adversarial evaluation approach in \"Generating Sentences from a Continuous Space\"\n",
        "(Bowman et al., 2016), we use pretrained LSTM logistic classifier available from [1]\n",
        "on samples of input texts and output texts for each style transfer model.\n",
        "Via adversarial evaluation, the classifiers must distinguish human-generated inputs from machine-generated outputs.\n",
        "The more natural an output is, the likelier it is to fool an adversarial classifier.\n",
        "\n",
        "    - Calculate naturalness scores for texts with clf, a NaturalnessClassifier      -> clf.score(...)\n",
        "You can find examples of more detailed usage commands below.\n",
        "\"\"\"\n",
        "\n",
        "NATURALNESS_CLASSIFIER_BASE_PATH = '/content/drive/My Drive/NaturalnessClassifier/'\n",
        "MAX_SEQ_LEN = 30 # for neural classifier\n",
        "\n",
        "def load_model(path):\n",
        "    return joblib.load(path)\n",
        "\n",
        "def invert_dict(dictionary):\n",
        "    return dict(zip(dictionary.values(), dictionary.keys()))\n",
        "\n",
        "TEXT_VECTORIZER = load_model('/content/drive/My Drive/vectorizer.pkl')\n",
        "\n",
        "# adjust vocabulary to account for unknowns\n",
        "VOCABULARY = TEXT_VECTORIZER.vocabulary_\n",
        "INVERSE_VOCABULARY = invert_dict(VOCABULARY)\n",
        "VOCABULARY[INVERSE_VOCABULARY[0]] = len(VOCABULARY)\n",
        "VOCABULARY['CUSTOM_UNKNOWN'] = len(VOCABULARY)+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## DATA PREP\n",
        "def convert_to_indices(text):\n",
        "    # tokenize input text\n",
        "    tokens = re.compile(RE_PATTERN).split(text)\n",
        "    non_empty_tokens = list(filter(lambda token: token, tokens))\n",
        "\n",
        "    indices = []\n",
        "\n",
        "    # collect indices of tokens in vocabulary\n",
        "    for token in non_empty_tokens:\n",
        "        if token in VOCABULARY:\n",
        "            index = VOCABULARY[token]\n",
        "        else:\n",
        "            index = VOCABULARY['CUSTOM_UNKNOWN']\n",
        "\n",
        "        indices.append(index)\n",
        "\n",
        "    return indices\n",
        "\n",
        "def format_inputs(texts):\n",
        "    # prepare texts for use in neural classifier\n",
        "    texts_as_indices = []\n",
        "    for text in texts:\n",
        "        texts_as_indices.append(convert_to_indices(text))\n",
        "    return pad_sequences(texts_as_indices, maxlen=MAX_SEQ_LEN, padding='post', truncating='post', value=0.)\n",
        "\n",
        "def merge_datasets(dataset1, dataset2):\n",
        "    x = []\n",
        "    x.extend(dataset1)\n",
        "    x.extend(dataset2)\n",
        "    return x\n",
        "\n",
        "def load_dataset(path):\n",
        "    data = []\n",
        "    with open(path) as f:\n",
        "        data.append(f.read())\n",
        "    data = [s.strip() for s in data]\n",
        "    return data\n",
        "\n",
        "\n",
        "    \n",
        "## NATURALNESS CLASSIFIERS\n",
        "class NaturalnessClassifier:\n",
        "    '''\n",
        "    An external classifier was trained for a style transfer model -\n",
        "    more specifically using its inputs and outputs excluding test samples.\n",
        "\n",
        "    Use UnigramBasedClassifier (TBD) or NeuralBasedClassifier to load a\n",
        "    trained classifier and score texts of a given style transfer model.\n",
        "    The scores represent the probabilities of the texts being 'natural'.\n",
        "\n",
        "    '''\n",
        "\n",
        "    pass\n",
        "\n",
        "class UnigramBasedClassifier(NaturalnessClassifier):\n",
        "    ''' \n",
        "    Might implement in future if neccessary\n",
        "\n",
        "    '''\n",
        "\n",
        "class NeuralBasedClassifier(NaturalnessClassifier):\n",
        "    def __init__(self, style_transfer_model_name):\n",
        "        self.path = f'{NATURALNESS_CLASSIFIER_BASE_PATH}/neural_{style_transfer_model_name}.h5'\n",
        "        self.classifier = load_keras_model(self.path)\n",
        "\n",
        "    def score(self, texts):\n",
        "        inps = format_inputs(texts)\n",
        "        distribution = self.classifier.predict(inps)\n",
        "        scores = distribution.squeeze()\n",
        "        return scores\n",
        "\n",
        "    def summary(self):\n",
        "        return self.classifier.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator CountVectorizer from version pre-0.18 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZbBqjuisRK7",
        "colab_type": "text"
      },
      "source": [
        "## Naturalness Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMyHw-Dzrlth",
        "colab_type": "code",
        "outputId": "ccb812c0-d765-4770-9714-70df522f71a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "model = 'CAAE' \n",
        "neural_classifier = NeuralBasedClassifier(model)\n",
        "print(neural_classifier.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Model: \"neural_adv_clf\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 30, 256)           2419456   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,616,705\n",
            "Trainable params: 2,616,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H80ZSpmjsW4i",
        "colab_type": "text"
      },
      "source": [
        "## Naturalness Scores for Donor Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLi10cs6snN7",
        "colab_type": "code",
        "outputId": "91d1aef5-87e0-4d40-a142-cc43a09011b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "twain_2 = [\"The question as to whether there is such a thing as divine right of kings is not settled in this book.  It was found too difficult. That the executive head of a nation should be a person of lofty character and extraordinary ability, was manifest and indisputable; that none but the Deity could select that head unerringly, was also manifest and indisputable; that the Deity ought to make that selection, then, was likewise manifest and indisputable; consequently, that He does make it, as claimed, was an unavoidable deduction. I mean, until the author of this book encountered the Pompadour, and Lady Castlemaine, and some other executive heads of that kind; these were found so difficult to work into the scheme, that it was judged better to take the other tack in this book (which must be issued this fall), and then go into training and settle the question in another book.  It is, of course, a thing which ought to be settled, and I am not going to have anything particular to do next winter anyway.\"]\n",
        "dumas_2 = [\"In the meanwhile, Monsieur continued his route with an air at once calm and majestic, and the more he thought about it, the less attractive he became of spectators, as there were too many spectators to keep up the exchange; but the good citizens of Blois could not pardon Monsieur for having chosen their gay city for an abode in which to indulge melancholy at his ease, and as often as they caught a glimpse of this demurecy, they stole away gaping, or drew back their heads into the interior of their dwellings, to wander again about and remain thus for a while. \"]\n",
        "not_real = ['Not naturalness is this, machine generated, flipped ngrams replacement decipher hard']\n",
        "\n",
        "print('Naturalness score for donors - twain_2 - ' + str(neural_classifier.score(twain_2)))\n",
        "print('Naturalness score for donors - dumas_2 - ' + str(neural_classifier.score(dumas_2)))\n",
        "print('Naturalness score for not real text - ' + str(neural_classifier.score(not_real)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naturalness score for donors - twain_2 - 0.94937\n",
            "Naturalness score for donors - dumas_2 - 0.9960622\n",
            "Naturalness score for not real text - 0.029273724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKHx3nHlsNMj",
        "colab_type": "code",
        "outputId": "5874f025-8dc5-4f24-f416-3af07a1f9f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/donor.csv')\n",
        "texts = df['text'].tolist()\n",
        "scores = neural_classifier.score(texts)\n",
        "df['naturalness_score'] = scores\n",
        "df.sample(10)\n",
        "#df.to_csv('donor_results_caae.csv', index=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>naturalness_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>that, having accidentally solved “the riddle ...</td>\n",
              "      <td>Nabokov</td>\n",
              "      <td>0.795369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>to be spread that Gorenflot had nearly persua...</td>\n",
              "      <td>Dumas</td>\n",
              "      <td>0.993022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>canvases; a poet, whose special gag was the a...</td>\n",
              "      <td>Nabokov</td>\n",
              "      <td>0.967813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>the reason or object of such a declaration; a...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>0.996486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>to reason away in Fanny. She feared for Willi...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>0.924784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>the wishes of his mother and sister, who long...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>0.995503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>traversed by the black bend-let of a branch. ...</td>\n",
              "      <td>Nabokov</td>\n",
              "      <td>0.897903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>“yes, this is just the account the duke gave ...</td>\n",
              "      <td>Dumas</td>\n",
              "      <td>0.968671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>ears do not remain there. Your highness wishe...</td>\n",
              "      <td>Dumas</td>\n",
              "      <td>0.986693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>of complacency, which prevented her from bein...</td>\n",
              "      <td>Austen</td>\n",
              "      <td>0.961801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ... naturalness_score\n",
              "109   that, having accidentally solved “the riddle ...  ...          0.795369\n",
              "327   to be spread that Gorenflot had nearly persua...  ...          0.993022\n",
              "67    canvases; a poet, whose special gag was the a...  ...          0.967813\n",
              "153   the reason or object of such a declaration; a...  ...          0.996486\n",
              "208   to reason away in Fanny. She feared for Willi...  ...          0.924784\n",
              "237   the wishes of his mother and sister, who long...  ...          0.995503\n",
              "7     traversed by the black bend-let of a branch. ...  ...          0.897903\n",
              "266   “yes, this is just the account the duke gave ...  ...          0.968671\n",
              "271   ears do not remain there. Your highness wishe...  ...          0.986693\n",
              "234   of complacency, which prevented her from bein...  ...          0.961801\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArBMt3antTg0",
        "colab_type": "text"
      },
      "source": [
        "## Ingested Style Transfered Data for Different Authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVryEup4tXuF",
        "colab_type": "code",
        "outputId": "a188dd57-ead8-405b-c4f0-5abfdee614a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "results = []\n",
        "for root, dirs, files in os.walk(\"/content/drive/My Drive\"):\n",
        "    for file in files:\n",
        "        if file.endswith(\".txt\"):\n",
        "            path = os.path.join(root, file)   \n",
        "            data = load_dataset(path)\n",
        "            score = neural_classifier.score(data)\n",
        "            print(path + ' - ' + str(score))\n",
        "            results.append([path, ' '.join(data), score])\n",
        "\n",
        "\n",
        "austen_path = '/content/drive/My Drive/Nabokov-style/Austen_raw/'\n",
        "os.chdir(austen_path)\n",
        "files = glob.glob('*.txt???')\n",
        "for file in files:\n",
        "  path = austen_path + file\n",
        "  data = load_dataset(path)\n",
        "  score = neural_classifier.score(data)\n",
        "  print(path + ' - ' + str(score))\n",
        "  results.append([path, ' '.join(data), score])\n",
        "\n",
        "\n",
        "dumas_path = '/content/drive/My Drive/Nabokov-style/Dumas_raw/'\n",
        "os.chdir(dumas_path)\n",
        "files = glob.glob('*.txt???')\n",
        "for file in files:\n",
        "  path = dumas_path + file\n",
        "  data = load_dataset(path)\n",
        "  score = neural_classifier.score(data)\n",
        "  print(path + ' - ' + str(score))\n",
        "  results.append([path, ' '.join(data), score])\n",
        "\n",
        "results = pd.DataFrame(results, columns=['file_name', 'text', 'naturalness'])\n",
        "results.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/rand_donor_original.txt - 0.93960655\n",
            "/content/drive/My Drive/misc (Nabokov style)/Austen/Austen_117M_10000_Nabokov-All-3.txt - 0.991459\n",
            "/content/drive/My Drive/misc (Nabokov style)/Austen/Austen-original.txt - 0.9612681\n",
            "/content/drive/My Drive/misc (Nabokov style)/Austen/Austen-original-2.txt - 0.9915976\n",
            "/content/drive/My Drive/misc (Nabokov style)/Austen/Austen_117M_10000_Nabokov-All-2.txt - 0.9815973\n",
            "/content/drive/My Drive/misc (Nabokov style)/Austen/Austen_117M_10000_Nabokov-All.txt - 0.9508127\n",
            "/content/drive/My Drive/misc (Nabokov style)/Shakespeare/Shakespeare_117M_10000_Nabokov-All.txt - 0.99463415\n",
            "/content/drive/My Drive/misc (Nabokov style)/Shakespeare/Shake__117M_10000_Nabokov-All.txt - 0.95405936\n",
            "/content/drive/My Drive/misc (Nabokov style)/Rand/output-nabovokov-12k-117M-reject10000-2.txt - 0.99902236\n",
            "/content/drive/My Drive/misc (Nabokov style)/Rand/output-nabovokov-12k-117M-reject1000.txt - 0.93960655\n",
            "/content/drive/My Drive/misc (Nabokov style)/Rand/output-nabovokov-2k-117M-reject100.txt - 0.9954855\n",
            "/content/drive/My Drive/misc (Nabokov style)/Rand/Rand_117M_10000_Nabokov-All-3.txt - 0.9881414\n",
            "/content/drive/My Drive/misc (Nabokov style)/Rand/output-nabovokov-12k-117M-reject10000.txt - 0.99207956\n",
            "/content/drive/My Drive/misc (Nabokov style)/Twain/Twain_117M_10000_Nabokov-All.txt - 0.8452722\n",
            "/content/drive/My Drive/misc (Nabokov style)/Twain/Twain-Miss_117M_10000_Nabokov-All.txt - 0.9983461\n",
            "/content/drive/My Drive/misc (Nabokov style)/Dumas/Dumas_117M_10000_Nabokov-All.txt - 0.995265\n",
            "/content/drive/My Drive/misc (Nabokov style)/Dumas/Dumas-long_117M_10000_Nabokov-All.txt - 0.9960622\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt124 - 0.9559204\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt123 - 0.95452976\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt122 - 0.9954152\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt125 - 0.9922362\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt126 - 0.9950565\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt129 - 0.98393065\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt128 - 0.6799744\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt127 - 0.99175656\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt120 - 0.9931804\n",
            "/content/drive/My Drive/Nabokov-style/Austen_raw/Trained-21K_345M_10000_Nabokov-All.txt121 - 0.99568534\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt241 - 0.96435803\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt249 - 0.98469156\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt248 - 0.9833487\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt240 - 0.32711643\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt246 - 0.9787794\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt247 - 0.99342316\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt244 - 0.9963863\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt242 - 0.99179465\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt245 - 0.878864\n",
            "/content/drive/My Drive/Nabokov-style/Dumas_raw/Trained-21K-Dumas_345M_10000_Nabokov-All.txt243 - 0.97784024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "      <th>naturalness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/My Drive/rand_donor_original.txt</td>\n",
              "      <td>She sat at the window of the train, her head t...</td>\n",
              "      <td>0.93960655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Mary had neither genius nor taste; but her day...</td>\n",
              "      <td>0.991459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Elizabeth listened in silence, but was not con...</td>\n",
              "      <td>0.9612681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Mary had neither genius nor taste; and though ...</td>\n",
              "      <td>0.9915976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Mary had neither genius nor taste; her only en...</td>\n",
              "      <td>0.9815973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           file_name  ... naturalness\n",
              "0    /content/drive/My Drive/rand_donor_original.txt  ...  0.93960655\n",
              "1  /content/drive/My Drive/misc (Nabokov style)/A...  ...    0.991459\n",
              "2  /content/drive/My Drive/misc (Nabokov style)/A...  ...   0.9612681\n",
              "3  /content/drive/My Drive/misc (Nabokov style)/A...  ...   0.9915976\n",
              "4  /content/drive/My Drive/misc (Nabokov style)/A...  ...   0.9815973\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D32KrfZnu-Gw",
        "colab_type": "text"
      },
      "source": [
        "## Processing for Style Transfer Text & Rescoring\n",
        "* remove non asci\n",
        "* remove special characeters like . --, -, |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTUKV6HNuZEs",
        "colab_type": "code",
        "outputId": "208a20dd-32d0-4407-8aa7-96565691359b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "def remove_non_ascii(text):\n",
        "    return ''.join(i for i in text if ord(i)<128)\n",
        " \n",
        "results['text_ascii_only'] = results['text'].apply(remove_non_ascii).str.replace('--|-|_', ',')\n",
        "texts = results['text_ascii_only'].tolist()\n",
        "scores = neural_classifier.score(texts)\n",
        "results['naturalness_ascii_only'] = scores\n",
        "results.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>text</th>\n",
              "      <th>naturalness</th>\n",
              "      <th>text_ascii_only</th>\n",
              "      <th>naturalness_ascii_only</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/My Drive/rand_donor_original.txt</td>\n",
              "      <td>She sat at the window of the train, her head t...</td>\n",
              "      <td>0.93960655</td>\n",
              "      <td>She sat at the window of the train, her head t...</td>\n",
              "      <td>0.939606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Mary had neither genius nor taste; but her day...</td>\n",
              "      <td>0.991459</td>\n",
              "      <td>Mary had neither genius nor taste; but her day...</td>\n",
              "      <td>0.995231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Elizabeth listened in silence, but was not con...</td>\n",
              "      <td>0.9612681</td>\n",
              "      <td>Elizabeth listened in silence, but was not con...</td>\n",
              "      <td>0.961268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Mary had neither genius nor taste; and though ...</td>\n",
              "      <td>0.9915976</td>\n",
              "      <td>Mary had neither genius nor taste; and though ...</td>\n",
              "      <td>0.991598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/My Drive/misc (Nabokov style)/A...</td>\n",
              "      <td>Mary had neither genius nor taste; her only en...</td>\n",
              "      <td>0.9815973</td>\n",
              "      <td>Mary had neither genius nor taste; her only en...</td>\n",
              "      <td>0.981597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           file_name  ... naturalness_ascii_only\n",
              "0    /content/drive/My Drive/rand_donor_original.txt  ...               0.939606\n",
              "1  /content/drive/My Drive/misc (Nabokov style)/A...  ...               0.995231\n",
              "2  /content/drive/My Drive/misc (Nabokov style)/A...  ...               0.961268\n",
              "3  /content/drive/My Drive/misc (Nabokov style)/A...  ...               0.991598\n",
              "4  /content/drive/My Drive/misc (Nabokov style)/A...  ...               0.981597\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP01ULLSzhHP",
        "colab_type": "text"
      },
      "source": [
        "## Save Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_vrzOzzHTvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive')\n",
        "#results.to_csv('All_Results.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v0BPrTqNCux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
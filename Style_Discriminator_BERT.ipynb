{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Style_Discriminator_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4-fSro-v_v-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "4ffbd661-bc65-4dc9-89d8-cd3afca0017d"
      },
      "source": [
        "# Install the required modules\n",
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install tqdm\n",
        "!pip install sklearn\n",
        "\n",
        "# !nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: requests in /tensorflow-2.0.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.0.0/python3.6 (from transformers) (1.17.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.13)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.0.0/python3.6 (from requests->transformers) (1.25.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.13 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.0.0/python3.6 (from sacremoses->transformers) (1.13.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.13->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.13->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /tensorflow-2.0.0/python3.6 (from pandas) (1.17.4)\n",
            "Requirement already satisfied: six>=1.5 in /tensorflow-2.0.0/python3.6 (from python-dateutil>=2.6.1->pandas) (1.13.0)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.0.0/python3.6 (1.17.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /tensorflow-2.0.0/python3.6 (from scikit-learn->sklearn) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuAmirw-wSEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9OtFNVx0vB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Embeddings:\n",
        "    LAST_LAYER = 1\n",
        "    def __init__(self):\n",
        "        self._tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self._bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "        self._bert_model.eval()\n",
        "\n",
        "    def tokenize(self, sentence):\n",
        "        \"\"\"\n",
        "\n",
        "        :param sentence: input sentence ['str']\n",
        "        :return: tokenized sentence based on word piece model ['List']\n",
        "        \"\"\"\n",
        "        marked_sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
        "        tokenized_text = self._tokenizer.tokenize(marked_sentence)\n",
        "        return tokenized_text\n",
        "\n",
        "    def get_bert_embeddings(self, sentence):\n",
        "        \"\"\"\n",
        "\n",
        "        :param sentence: input sentence ['str']\n",
        "        :return: BERT pre-trained hidden states (list of torch tensors) ['List']\n",
        "        \"\"\"\n",
        "        # Predict hidden states features for each layer\n",
        "\n",
        "        tokenized_text = self.tokenize(sentence)\n",
        "        indexed_tokens = self._tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "        segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "        # Convert inputs to PyTorch tensors\n",
        "        tokens_tensor = torch.tensor([indexed_tokens])\n",
        "        segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            encoded_layers = self._bert_model(tokens_tensor, segments_tensors)\n",
        "\n",
        "        return encoded_layers[-1][0:12]\n",
        "\n",
        "    def sentence2vec(self, sentence, layers):\n",
        "        \"\"\"\n",
        "\n",
        "        :param sentence: input sentence ['str']\n",
        "        :param layers: parameter to decide how word embeddings are obtained ['str]\n",
        "            1. 'last' : last hidden state used to obtain word embeddings for sentence tokens\n",
        "            2. 'last_4' : last 4 hidden states used to obtain word embeddings for sentence tokens\n",
        "\n",
        "        :return: sentence vector [List]\n",
        "        \"\"\"\n",
        "        encoded_layers = self.get_bert_embeddings(sentence)\n",
        "        \n",
        "        if layers == 1:\n",
        "            # using the last layer embeddings\n",
        "            token_embeddings = encoded_layers[-1]\n",
        "            # summing the last layer vectors for each token\n",
        "            sentence_embedding = torch.mean(token_embeddings, 1)\n",
        "            return sentence_embedding.view(-1).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBmksfP_04cH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/fy164251/text_style_transfer/master/Datasets/raw_text.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "X = df.text.astype('str')\n",
        "y = df.author.astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD1A_uzX-mUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88a982db-f167-48ca-ba78-e73f8600c9b4"
      },
      "source": [
        "model = Embeddings()\n",
        "\n",
        "X_text = []\n",
        "for sentence in tqdm(X):\n",
        "    X_text.append(model.sentence2vec(sentence, layers=model.LAST_LAYER))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|‚ñè         | 532/35874 [03:13<3:26:34,  2.85it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY3FCnoh-zc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}